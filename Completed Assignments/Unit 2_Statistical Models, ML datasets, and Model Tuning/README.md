Unit 2: Project Descriptions

Technical:

Unit 2, like all other units, has been broken up into multiple sections so that we may learn new skills and build old ones. We began this unit by learning about linear Models and how to use Python Libraries such as SciKit Learn to create and explain the results from those models. We dove deeper into the kinds of models we could create such as Linear Regression, Logistic Regression, Ridge Regression as well as Decision Trees. We also explored ways to split and clean data to make our models purer with processes like OneHotEncoding, creating baselines, and understanding Over/Underfitting.

In the next section, we learned about Random Forests, Cross-validation, and methods for classification. We dove deeper into overfitting and underfitting which led us to discuss the tuning of hyperparameters and the methods that make that process easier. We briefly touched on confusion matrices as well as measurements such as precision, recall, and thresholds. We ended this section with a Kaggle challenge where the goal was to get the highest accuracy score for an unseen set of test data.

In the last section of this unit we put together what we had learned about modeling, Pipelines, and data wrangling (cleaning) and took a step towards learning how to set up our data for supervised Machine Learning. This included using libraries such as XGBoost and GradientBoost to change the weights in the model to boost the recognition of classes for classification problems. We ended this unit by exploring Shapley value plots, permutation importance, and ROC AUC metrics.

The overarching reason behind advancing our knowledge of these technical aspects is that it gives us a wide range of options to consider when faced with a challenge. It allows us to understand what is possible, even if we don't have a full understanding of why and when we should use these processes. Being able to recognize what isn't possible is just as important as recognizing what is. We used a wide variety of datasets during this unit so that we could practice wrangling data on a wider scale and with a mix of issues. Our processes corrected errors in data gathering, modified existing data to find unseen information and created predictive models to allow us to easily predict what might happen in the future. The benefits of these processes are seen in the ease of use for non-technical personnel, the identification of issues of efficiency or cost-effectiveness, and changes to the business model that result in an increase in revenue. 


Non-Technical:

In this field there are many important details to be aware of as a tiny change during the beginning of the process can have a huge difference in the quality of the outcome. For example, in this unit we learned about the importance of choosing the right way of doing things from the beginning. If we set out to complete an objective that when finished produces unsavory results, we have to redo a lot of our work. To be able to choose correctly we need to know about the majority of the options available. However, fully understanding how each process works is not our sole objective. With a basic understanding of what we expect to happen and exposure to the limits of what we can do, our choices are limited, and therefore much easier to pick a process that will work in our favor. We then began to learn about how to make that observation, objectively clear. 

After we have made a decision and chosen a process we need a way to verify that the process we chose was in fact the correct one to choose. We also need a way to show how accurate our process was at the objective we set out to complete. To do this we need a way to make quantifiable measurements that objectively show us which process has better results. In this section we learned about different kinds of measurements and how each of them is important as well as how to implement them. One of the most important factors in determining the objective quality of our model is if the model itself was influenced by our implementation. If we allowed the model access to answers unintentionally we could be very pleased by the quantifiable results but instead could have created a model that is entirely non-functional. This is something we would very much like to avoid and as a result we dove deeper into the process of implementation and measurement so that we could recognize this issue before it happened.

Without the knowledge provided to us through the process of quantifying our results we wouldn’t be able to be confident that our model is working as intended especially when we move on to more advanced techniques of prediction and modeling. In a customer oriented environment It is very important to be able to objectively state the quality of our model based on the data given to us as well as give suggestions for improving the quality or quantity of data. Being able to properly communicate the choices made, the style and effectiveness of the model are critically important. If the customer doesn't understand, even at a very basic level, what the purpose of these models is they will be hesitant to use your suggestions even if it is obviously beneficial. This is why easily understandable measurements and technical communication is a very important skill.

This section was designed to expose us to the limits and options available to use during this process as well as furthering our experience using the tools and logic to create processes that work. If we can explain to ourselves why and how these processes are used we will be able to make better informed choices from the beginning, lowering the cost of labor and increasing the efficiency of the process. It has been made clear that the problems we are tasked with solving are not only prediction and accuracy but also communication with coworkers and customers.
